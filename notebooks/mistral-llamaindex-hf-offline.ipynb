{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Mistral 7B Offline RAG with Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/simple-rag-1-reranker.webp\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the embedding model and LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dk\\anaconda3\\envs\\rag\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dk\\anaconda3\\envs\\rag\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dk\\anaconda3\\envs\\rag\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dk\\anaconda3\\envs\\rag\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\dk\\anaconda3\\envs\\rag\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4ec9947d8745a29d5d3bd88c3e2622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "import torch\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    context_window=2048,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"do_sample\": False},\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.bfloat16,\n",
    "        # Since we are using a small GPU with limited memory\n",
    "        # Set to False if you have a large GPU to speed things up.\n",
    "        \"offload_buffers\": True, \n",
    "    }\n",
    ")\n",
    "\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Load data / read in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read documents: {'Basic-Scientific-Food-Preparation-Lab-Manual.pdf', 'Basic-Scientific-Food-Preparation-Lab-Manual.txt'}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "data_dir =  Path(\"..\") / \"data\" / \"example-1\"\n",
    "\n",
    "documents = SimpleDirectoryReader(data_dir).load_data()\n",
    "\n",
    "# Sanity checks\n",
    "unique_docs = set(d.metadata[\"file_name\"] for d in documents)\n",
    "print(f\"Read documents: {unique_docs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create vector database\n",
    "\n",
    "- VectorStoreIndex is an in-memory vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c876b7a8749ad829f86882f8611fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d078acedb8447a903549839cb68657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dk\\anaconda3\\envs\\rag\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database consists of 252 chunks\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "num_chunks = len(documents)\n",
    "print(f\"Database consists of {num_chunks} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Set up custom prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = (\n",
    "    \"We have provided context information below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this information, please answer the question: {query_str}\\n\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "query_engine = index.as_query_engine()\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Query the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dehydration is a process used to preserve food by removing moisture from it. It can be done through various methods such as sun drying, oven drying, or using a dehydrator. The objective of dehydration is to prevent bacterial growth and extend the shelf life of food. The dehydrated food can be stored in a cool place or rehydrated for consumption. In this lab manual, students are instructed to pretreat, dry, store, and serve some commonly dehydrated fruits and vegetables, and observe the characteristics of various dried fruits. The manual also provides specific directions for pretreating different fruits and vegetables to control enzymatic deterioration before dehydration.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is dehydration?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: 2 tbsp. butter are required for the Cream Puffs.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How many tbsp. butter to use for the Cream Puffs?\")\n",
    "print(response)\n",
    "# Correct answer is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The toppings for the Braided Bread in the Braids, Coffeecake, and Sweet Rolls recipe are:\n",
      "\n",
      "1. 2 tsp. caraway seeds and ½ cup shredded Cheddar cheese.\n",
      "2. ½ cup diced Swiss cheese and paprika.\n",
      "\n",
      "For the Braided Pineapple Coffeecake, the topping is:\n",
      "\n",
      "1. ⅓ cup shredded coconut\n",
      "2. 1 tbsp. melted butter\n",
      "3. ½ cup well-drained, crushed pineapple\n",
      "4. 1 egg white\n",
      "5. 3 tbsp. brown sugar\n",
      "6. ⅛ tsp. cinnamon\n",
      "\n",
      "For the Butterscotch Rolls, the topping is:\n",
      "\n",
      "1. ¼ cup brown sugar\n",
      "2. 2 tbsp. butter\n",
      "3. 1 tsp. light corn syrup\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are the toppings for the Braided Bread \"\n",
    "    \"of the Braids, Coffeecake, and Sweet Rolls recipe?\"\n",
    ")\n",
    "print(response)\n",
    "# Correct answer is \n",
    "# 2 tsp. caraway seeds and ½ cup shredded Cheddar cheese.\n",
    "# ½ cup diced Swiss cheese and paprika.\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
